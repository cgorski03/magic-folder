# Magic Folder C++

An intelligent file management system leveraging locally-run LLMs and embedding models to organize and classify your files with an unyielding commitment to privacy and performance.

## ğŸ¯ Project Status: MVP with Roadmap

**Current State**: Basic file indexing and semantic search working with single-file processing
**Next Phase**: Advanced chunking system with worker pools for scalable processing

## ğŸ—ï¸ Architecture Overview

Magic Folder C++ is a C++ implementation that automatically processes files, generates embeddings using Ollama, and enables semantic search across your document collection. The system is designed with a layered architecture:

### Core Components

- **`magic-core`**: Core business logic for file processing, vector storage, and embeddings
- **`magic-api`**: REST API server with background worker pools
- **`magic-cli`**: Command-line interface for system interaction

### Current MVP Features âœ…

- âœ… Basic file content extraction (text, markdown, code files)
- âœ… Content hashing for change detection
- âœ… Embedding generation via Ollama (`mxbai-embed-large`)
- âœ… SQLite metadata storage with FAISS vector search
- âœ… REST API endpoints for file processing and search
- âœ… CLI interface for system interaction
- âœ… Comprehensive test coverage

### Next Phase Features ğŸš§

- ğŸš§ **Advanced Chunking System**: Multi-level content chunking with semantic boundaries
- ğŸš§ **Worker Pool Architecture**: Asynchronous background processing
- ğŸš§ **Task Queue System**: Reliable job processing with retry logic
- ğŸš§ **Enhanced Search**: Two-stage search (file-level + chunk-level)
- ğŸš§ **File Watching**: Real-time file system monitoring

## ğŸ“‹ Development Roadmap

### Phase 1: Chunking System Overhaul (Priority 1)

#### 1.1 Content Extractor Refactoring
- [ ] **Create `Chunk.h` structure**
  - [ ] Define `Chunk` struct with content, metadata, and vector fields
  - [ ] Add chunk indexing and ordering logic
  - [ ] Implement chunk-level content hashing

- [ ] **Implement `ContentExtractorFactory`**
  - [ ] Create factory pattern for file type detection
  - [ ] Add support for multiple extractor types
  - [ ] Implement fallback to `PlainTextExtractor`

- [ ] **Build `MarkdownExtractor`**
  - [ ] Parse markdown structure (headers, sections, lists)
  - [ ] Create semantic chunk boundaries
  - [ ] Preserve markdown formatting in chunks
  - [ ] Add metadata extraction (title, headings, links)

- [ ] **Enhance `PlainTextExtractor`**
  - [ ] Implement paragraph-based chunking
  - [ ] Add sentence boundary detection
  - [ ] Handle special characters and encoding
  - [ ] Add content cleaning and normalization

#### 1.2 Database Schema Updates
- [ ] **Update `Files` table**
  - [ ] Add `summary_vector_blob` for file-level embeddings
  - [ ] Add `processing_status` field
  - [ ] Add `suggested_category` and `suggested_filename` fields
  - [ ] Add `tags` JSON field

- [ ] **Create `Chunks` table**
  - [ ] Implement chunk storage with file relationships
  - [ ] Add chunk indexing and ordering
  - [ ] Store chunk-level vectors
  - [ ] Add content hashing for chunks

- [ ] **Create `TaskQueue` table**
  - [ ] Implement task status tracking
  - [ ] Add priority and error handling
  - [ ] Support task retry logic

#### 1.3 Search System Enhancement
- [ ] **Two-Stage Search Implementation**
  - [ ] Stage 1: File-level similarity search
  - [ ] Stage 2: Chunk-level precision search
  - [ ] Implement result ranking and scoring
  - [ ] Add search result highlighting

- [ ] **Memory Index Management**
  - [ ] Load summary vectors at startup
  - [ ] Implement chunk index loading
  - [ ] Add index rebuilding capabilities
  - [ ] Optimize memory usage

### Phase 2: Worker Pool Architecture (Priority 2)

#### 2.1 Async Infrastructure
- [ ] **Create `Worker.h` interface**
  - [ ] Define worker thread lifecycle
  - [ ] Add task processing interface
  - [ ] Implement error handling and recovery
  - [ ] Add worker health monitoring

- [ ] **Implement `WorkerPool.h`**
  - [ ] Create thread pool management
  - [ ] Add load balancing logic
  - [ ] Implement graceful shutdown
  - [ ] Add worker pool configuration

- [ ] **Database Integration**
  - [ ] Create `DatabaseManager.h` for connection pooling
  - [ ] Implement `TaskQueue.h` for job management
  - [ ] Add transaction handling
  - [ ] Implement connection retry logic

#### 2.2 Background Processing
- [ ] **Task Processing Pipeline**
  - [ ] Implement task polling mechanism
  - [ ] Add task status updates
  - [ ] Create error handling and retry logic
  - [ ] Add progress tracking

- [ ] **File System Integration**
  - [ ] Implement file watching capabilities
  - [ ] Add file change detection
  - [ ] Create automatic task creation
  - [ ] Add file move/rename handling

### Phase 3: Enhanced Features (Priority 3)

#### 3.1 Advanced Content Processing
- [ ] **PDF Support**
  - [ ] Integrate PDF text extraction library
  - [ ] Handle PDF structure and formatting
  - [ ] Add PDF metadata extraction
  - [ ] Implement PDF chunking strategies

- [ ] **Code File Enhancement**
  - [ ] Add syntax-aware chunking
  - [ ] Implement function/class boundary detection
  - [ ] Add code comment extraction
  - [ ] Create code-specific search features

#### 3.2 Search and UI Improvements
- [ ] **Advanced Search Features**
  - [ ] Add search filters (file type, date, size)
  - [ ] Implement search result pagination
  - [ ] Add search history and suggestions
  - [ ] Create search result export

- [ ] **Performance Optimizations**
  - [ ] Implement vector caching
  - [ ] Add search result caching
  - [ ] Optimize database queries
  - [ ] Add background index maintenance

## ğŸ› ï¸ Installation & Setup

### Prerequisites

1. **C++20 Compatible Compiler**: GCC 10+, Clang 12+, or MSVC 2019+
2. **CMake**: Version 3.20 or higher
3. **Ollama**: Local Ollama server with embedding model

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull the required embedding model
ollama pull mxbai-embed-large

# Start Ollama server
ollama serve
```

4. **Dependencies**:
   - libcurl (HTTP client)
   - nlohmann-json (JSON parsing)
   - sqlite3 (Database)
   - OpenSSL (Cryptographic functions)
   - FAISS (Vector similarity search)

### Installation

#### Ubuntu/Debian
```bash
sudo apt update
sudo apt install build-essential cmake libcurl4-openssl-dev nlohmann-json3-dev libsqlite3-dev libssl-dev
```

#### macOS
```bash
# Using Homebrew
brew install cmake curl nlohmann-json sqlite openssl

# Using MacPorts
sudo port install cmake curl nlohmann-json sqlite3 openssl
```

#### Windows
```bash
# Using vcpkg
vcpkg install curl nlohmann-json sqlite3 openssl faiss
```

### Building

```bash
# Clone and navigate
cd magic-folder-cpp

# Create build directory
mkdir build && cd build

# Configure and build
cmake ..
make -j$(nproc)  # Linux/macOS
# or
cmake --build . --config Release  # Windows
```

## âš™ï¸ Configuration

Create a `.env` file in the project root:

```bash
# API Configuration
API_BASE_URL=127.0.0.1:3030

# Database Paths
VECTOR_DB_PATH=./data/vector_db
METADATA_DB_PATH=./data/metadata.db

# Ollama Configuration
OLLAMA_URL=http://localhost:11434
EMBEDDING_MODEL=mxbai-embed-large

# Worker Pool Configuration
WORKER_POOL_SIZE=4
TASK_QUEUE_POLL_INTERVAL=1000

# File Watching
WATCHED_FOLDER=./watched_files
```

## ğŸš€ Usage

### 1. Start the API Server

```bash
# From the build directory
./bin/magic_api
```

The server starts on `http://localhost:3030` with background worker pools.

### 2. Use the CLI

**Process a file**:
```bash
./bin/magic_cli process --file path/to/your/file.txt
```

**Search for files**:
```bash
./bin/magic_cli search --query "your search query" --top-k 5
```

**List all files**:
```bash
./bin/magic_cli list
```

**Check system status**:
```bash
./bin/magic_cli status
```

### 3. API Endpoints

- `GET /` - Health check
- `POST /process_file` - Process a file for indexing
- `POST /search` - Search for files using semantic search
- `GET /files` - List all indexed files
- `GET /files/{path}` - Get information about a specific file
- `DELETE /files/{path}` - Delete a file from the index
- `GET /status` - Get system status and worker pool info

## ğŸ“ Project Structure

### Current Structure (MVP)

```
magic-folder-cpp/
â”œâ”€â”€ .env                      # Configuration (DB paths, Ollama URL, worker count)
â”œâ”€â”€ .gitignore                # Files to ignore for version control
â”œâ”€â”€ CMakeLists.txt            # Root CMake file
â”œâ”€â”€ LICENSE                   # Project license
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ SystemDesignDiagrams.md   # System architecture diagrams
â”œâ”€â”€ TESTING.md                # Testing documentation
â”œâ”€â”€ vcpkg.json                # Package dependencies
â”œâ”€â”€ build.sh                  # Build script
â”œâ”€â”€ run_tests.sh              # Test runner script
â”‚
â”œâ”€â”€ data/                     # Runtime data (gitignored)
â”‚   â””â”€â”€ metadata.db           # SQLite database
â”‚
â”œâ”€â”€ include/                  # PUBLIC HEADERS
â”‚   â”œâ”€â”€ magic_core/           # Core library headers
â”‚   â”‚   â”œâ”€â”€ content_extractor.hpp    # Content extraction interface
â”‚   â”‚   â”œâ”€â”€ metadata_store.hpp       # Database and vector storage
â”‚   â”‚   â”œâ”€â”€ ollama_client.hpp        # Ollama API client
â”‚   â”‚   â”œâ”€â”€ types.hpp                # Core type definitions
â”‚   â”‚   â””â”€â”€ file_watcher.hpp         # File system monitoring
â”‚   â”‚
â”‚   â”œâ”€â”€ magic_api/            # API server headers
â”‚   â”‚   â”œâ”€â”€ config.hpp        # Server configuration
â”‚   â”‚   â”œâ”€â”€ routes.hpp        # HTTP route handlers
â”‚   â”‚   â””â”€â”€ server.hpp        # Server interface
â”‚   â”‚
â”‚   â”œâ”€â”€ magic_services/       # Service layer headers
â”‚   â”‚   â”œâ”€â”€ file_processing_service.hpp  # File processing orchestration
â”‚   â”‚   â”œâ”€â”€ search_service.hpp           # Semantic search service
â”‚   â”‚   â”œâ”€â”€ file_info_service.hpp       # File metadata service
â”‚   â”‚   â”œâ”€â”€ file_delete_service.hpp     # File deletion service
â”‚   â”‚   â””â”€â”€ background/                 # Background processing
â”‚   â”‚
â”‚   â””â”€â”€ magic_cli/            # CLI headers
â”‚       â””â”€â”€ cli_handler.hpp   # Command-line interface
â”‚
â”œâ”€â”€ src/                      # IMPLEMENTATION
â”‚   â”œâ”€â”€ magic_core/           # Core library implementation
â”‚   â”‚   â”œâ”€â”€ content_extractor.cpp      # Content extraction logic
â”‚   â”‚   â”œâ”€â”€ metadata_store.cpp         # Database operations
â”‚   â”‚   â”œâ”€â”€ ollama_client.cpp          # Ollama API implementation
â”‚   â”‚   â”œâ”€â”€ types.cpp                  # Type implementations
â”‚   â”‚   â”œâ”€â”€ file_watcher.cpp           # File system monitoring
â”‚   â”‚   â””â”€â”€ CMakeLists.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ magic_api/            # API server executable
â”‚   â”‚   â”œâ”€â”€ main.cpp          # Server entry point
â”‚   â”‚   â”œâ”€â”€ server.cpp        # Server implementation
â”‚   â”‚   â”œâ”€â”€ routes.cpp        # HTTP endpoint handlers
â”‚   â”‚   â””â”€â”€ CMakeLists.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ magic_services/       # Service layer implementation
â”‚   â”‚   â”œâ”€â”€ file_processing_service.cpp # File processing logic
â”‚   â”‚   â”œâ”€â”€ search_service.cpp         # Search implementation
â”‚   â”‚   â”œâ”€â”€ file_info_service.cpp      # File metadata operations
â”‚   â”‚   â”œâ”€â”€ file_delete_service.cpp    # File deletion logic
â”‚   â”‚   â””â”€â”€ CMakeLists.txt
â”‚   â”‚
â”‚   â””â”€â”€ magic_cli/            # CLI executable
â”‚       â”œâ”€â”€ main.cpp          # CLI entry point
â”‚       â”œâ”€â”€ cli_handler.cpp   # CLI command handling
â”‚       â””â”€â”€ CMakeLists.txt
â”‚
â”œâ”€â”€ tests/                    # Unit and integration tests
â”‚   â”œâ”€â”€ test_file_processing_service.cpp # File processing tests
â”‚   â”œâ”€â”€ test_search_service.cpp         # Search functionality tests
â”‚   â”œâ”€â”€ test_file_delete_service.cpp    # File deletion tests
â”‚   â”œâ”€â”€ test_file_info_service.cpp      # File info tests
â”‚   â”œâ”€â”€ test_utilities.cpp              # Utility function tests
â”‚   â”œâ”€â”€ test_mocks.hpp                  # Mock objects for testing
â”‚   â”œâ”€â”€ test_utilities.hpp              # Test utilities
â”‚   â”œâ”€â”€ test_main.cpp                   # Test entry point
â”‚   â””â”€â”€ CMakeLists.txt
â”‚
â”œâ”€â”€ third_party/              # Third-party dependencies
â””â”€â”€ build/                    # Build output directory
```

### Future Structure (Phase 1+)

The core will be enhanced with the following structure:

```
include/magic_core/
â”œâ”€â”€ async/
â”‚   â”œâ”€â”€ Worker.h              # Worker thread interface
â”‚   â””â”€â”€ WorkerPool.h          # Worker pool management
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ DatabaseManager.h     # SQLite connection management
â”‚   â””â”€â”€ TaskQueue.h           # Task queue interface
â”œâ”€â”€ extractors/
â”‚   â”œâ”€â”€ ContentExtractor.h    # Abstract base class
â”‚   â”œâ”€â”€ ContentExtractorFactory.h # Factory pattern
â”‚   â”œâ”€â”€ MarkdownExtractor.h   # Markdown-specific extractor
â”‚   â””â”€â”€ PlainTextExtractor.h  # Fallback extractor
â”œâ”€â”€ llm/
â”‚   â””â”€â”€ OllamaClient.h        # Ollama API client
â””â”€â”€ Chunk.h                   # Chunk data structure
```

This future structure will be implemented during Phase 1 of the development roadmap.

## ğŸ”§ Development Status

### âœ… Completed (MVP)
- Basic project structure and CMake configuration
- Core component interfaces and implementations
- CLI argument parsing and API communication
- SQLite metadata storage with FAISS integration
- Content extraction for text files
- HTTP client implementation using libcurl
- Comprehensive test coverage

### ğŸš§ In Progress (Phase 1)
- Content extractor refactoring with chunking system
- Database schema updates for chunks and task queue
- Two-stage search implementation
- Memory index management

### âŒ Not Yet Implemented
- Worker pool architecture (Phase 2)
- Advanced file watching (Phase 2)
- PDF content extraction (Phase 3)
- Async operations (Phase 2)
- Performance optimizations (Phase 3)

## ğŸ§ª Testing

Run the test suite:

```bash
# From build directory
./bin/run_tests

# Or run specific tests
./bin/test_chunking
./bin/test_db
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License

## ğŸ”® Future Enhancements

### Phase 4: Advanced Features
- [ ] Docker containerization
- [ ] CI/CD pipeline
- [ ] Performance monitoring
- [ ] Advanced analytics
- [ ] Plugin system for custom extractors

### Phase 5: Enterprise Features
- [ ] Multi-user support
- [ ] Access control and permissions
- [ ] Audit logging
- [ ] Backup and restore
- [ ] Cluster deployment

## ğŸ› Troubleshooting

### Common Issues

1. **Ollama not running**: Start with `ollama serve`
2. **Missing dependencies**: Install all required libraries
3. **Build errors**: Ensure C++20 compiler and CMake 3.20+
4. **Permission errors**: Check write permissions for data directory
5. **Port conflicts**: Change API_BASE_URL in .env file

### Debug Mode

Enable debug logging by setting environment variables:
```bash
export MAGIC_FOLDER_DEBUG=1
export MAGIC_FOLDER_LOG_LEVEL=DEBUG
```

## ğŸ“Š Performance Notes

- **Current**: Single-threaded processing, ~1-2 files/second
- **Target (Phase 2)**: Multi-threaded with worker pools, ~10-20 files/second
- **Memory Usage**: ~100MB base + ~1MB per 1000 files
- **Storage**: ~1KB per file metadata + ~4KB per chunk vector

---

**Next Steps**: Start with Phase 1 - Content Extractor Refactoring to implement the chunking system foundation.
